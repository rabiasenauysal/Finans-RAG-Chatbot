# -*- coding: utf-8 -*-
"""finans-rag-chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DhYuMem6YYqioMdVWMjkl6vZDno7lIF1
"""

# ============================================================================
# 1. KURULUM VE BAÄIMLILIKLAR (DÃœZELTÄ°LMÄ°Å)
# ============================================================================

print("=" * 70)
print("ADIM 1: Gerekli kÃ¼tÃ¼phaneler kuruluyor (Uyumlu sÃ¼rÃ¼mlerle)...")
print("=" * 70)

# Ã–nce numpy'yi downgrade et (Ã§akÄ±ÅŸmalarÄ±n kaynaÄŸÄ±)
!pip install numpy==1.26.4 --force-reinstall -q

# LangChain Core ve Google Genai (pin'lenmiÅŸ sÃ¼rÃ¼mler)
!pip install langchain-core==0.3.79 langchain==0.3.27 langchain-community==0.3.31 langchain-google-genai==2.1.12 --force-reinstall -q

# Yeni HuggingFace Embeddings paketi (deprecated'i dÃ¼zeltir)
!pip install langchain-huggingface==0.1.0 -q

# PDF iÅŸleme
!pip install pypdf -q

# Embedding iÃ§in Sentence Transformers (yeniden yÃ¼kle, numpy sonrasÄ±)
!pip install sentence-transformers==3.1.1 -q  # Pin'lenmiÅŸ stabil sÃ¼rÃ¼m

# Vector Database iÃ§in FAISS
!pip install faiss-cpu -q

# Temizlik: Cache'leri temizle
import sys
sys.modules.pop('sentence_transformers', None)  # Eski import'u temizle

print("âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla kuruldu (Numpy downgrade ile)!\n")

# ============================================================================
# 2. VERSÄ°YON KONTROLÃœ VE API KEY
# ============================================================================

print("=" * 70)
print("ADIM 2: Versiyon kontrolÃ¼ ve API anahtarÄ± yÃ¼kleniyor...")
print("=" * 70)

import os
from google.colab import userdata
import langchain

# Versiyon bilgileri
print(f"ğŸ“¦ LangChain: {langchain.__version__}")
!pip show langchain-google-genai | grep Version
!pip show langchain-core | grep Version

# API Key yÃ¼kleme
try:
    os.environ["GOOGLE_API_KEY"] = userdata.get('GOOGLE_API_KEY')
    print("\nâœ… Google API AnahtarÄ± baÅŸarÄ±yla yÃ¼klendi.")
except:
    print("\nâš ï¸ UYARI: 'GOOGLE_API_KEY' Colab Secrets'e eklenmedi!")
    print("Sol menÃ¼den ğŸ”‘ Secrets bÃ¶lÃ¼mÃ¼ne gidin ve GOOGLE_API_KEY ekleyin.")

print()

# ============================================================================
# 3. GEREKLÄ° MODÃœLLER Ä°Ã‡E AKTARILIYOR (DÃœZELTÄ°LMÄ°Å)
# ============================================================================

print("=" * 70)
print("ADIM 3: ModÃ¼ller iÃ§e aktarÄ±lÄ±yor (GÃ¼ncellenmiÅŸ import'lar)...")
print("=" * 70)

try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
    from langchain_community.document_loaders import PyPDFLoader
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain.chains import RetrievalQA
    # DÃœZELTME: Eski import yerine yenisini kullan
    from langchain_huggingface import HuggingFaceEmbeddings  # Yeni paket
    print("âœ… TÃ¼m modÃ¼ller baÅŸarÄ±yla iÃ§e aktarÄ±ldÄ±!\n")
except Exception as e:
    print(f"âŒ ModÃ¼l iÃ§e aktarma hatasÄ±: {e}\n")
    raise

# ============================================================================
# 4. VERÄ° SETÄ° YÃœKLEME VE Ä°ÅLEME
# ============================================================================

print("=" * 70)
print("ADIM 4: Veri Seti (PDF) YÃ¼kleniyor ve Ä°ÅŸleniyor...")
print("=" * 70)

"""
VERÄ° SETÄ° HAKKINDA:
- Dosya AdÄ±: sozluk.pdf
- Ä°Ã§erik: Ekonomi terimleri sÃ¶zlÃ¼ÄŸÃ¼
- Format: PDF
- Kaynak: [Buraya veri kaynaÄŸÄ±nÄ± ekleyin]
- Toplam Sayfa: [PDF yÃ¼klendikten sonra gÃ¶rÃ¼lecek]

NOT: Bu dosyayÄ± Colab'Ä±n sol menÃ¼sÃ¼ndeki "Files" bÃ¶lÃ¼mÃ¼nden
/content/ dizinine yÃ¼klemeniz gerekmektedir.
"""

pdf_path = "/content/sozluk.pdf"

try:
    # PDF YÃ¼kleme
    loader = PyPDFLoader(pdf_path)
    docs = loader.load()
    print(f"âœ… PDF baÅŸarÄ±yla yÃ¼klendi")
    print(f"ğŸ“„ Toplam sayfa sayÄ±sÄ±: {len(docs)}")
    print(f"ğŸ“Š Ä°lk sayfadaki karakter sayÄ±sÄ±: {len(docs[0].page_content)}")

    # Ã–rnek iÃ§erik gÃ¶sterimi
    print("\nğŸ“– Ä°lk sayfadan Ã¶rnek iÃ§erik (ilk 200 karakter):")
    print("-" * 70)
    print(docs[0].page_content[:200] + "...")
    print("-" * 70)
    print()

except FileNotFoundError:
    print(f"âŒ HATA: '{pdf_path}' dosyasÄ± bulunamadÄ±!")
    print("ğŸ“ LÃ¼tfen PDF'i Colab'Ä±n sol menÃ¼sÃ¼nden /content/ dizinine yÃ¼kleyin.")
    raise
except Exception as e:
    print(f"âŒ PDF yÃ¼kleme hatasÄ±: {e}")
    raise

# ============================================================================
# 5. METÄ°N PARÃ‡ALAMA (CHUNKING)
# ============================================================================

print("=" * 70)
print("ADIM 5: Metin ParÃ§alara AyrÄ±lÄ±yor (Chunking)...")
print("=" * 70)

"""
CHUNKING STRATEJÄ°SÄ°:
- Chunk Size: 1000 karakter (Her parÃ§a ~200-250 kelime)
- Chunk Overlap: 100 karakter (BaÄŸlam kaybÄ±nÄ± Ã¶nlemek iÃ§in)
- Metod: RecursiveCharacterTextSplitter (HiyerarÅŸik bÃ¶lme)

NEDEN BU PARAMETRELER?
- 1000 karakter: Embedding modelleri iÃ§in optimal boyut
- 100 overlap: Terimlerin parÃ§alar arasÄ± kaybolmamasÄ± iÃ§in
- Recursive splitter: CÃ¼mle yapÄ±sÄ±nÄ± koruyarak bÃ¶ler
"""

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100,
    separators=["\n\n", "\n", " ", ""]
)

chunks = text_splitter.split_documents(docs)

print(f"âœ… DokÃ¼man {len(chunks)} parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼")
print(f"ğŸ“Š Ortalama chunk boyutu: {sum(len(c.page_content) for c in chunks) // len(chunks)} karakter")
print(f"\nğŸ“ Ã–rnek bir chunk:")
print("-" * 70)
print(chunks[0].page_content[:300] + "...")
print("-" * 70)
print()

# ============================================================================
# 6. EMBEDDING MODELÄ° VE VECTOR DATABASE (DÃœZELTÄ°LMÄ°Å)
# ============================================================================

print("=" * 70)
print("ADIM 6: Embedding Modeli YÃ¼kleniyor ve Vector DB OluÅŸturuluyor...")
print("=" * 70)

try:
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

    print(f"ğŸ¤– Embedding modeli yÃ¼kleniyor: {model_name}")
    # DÃœZELTME: Yeni import ile HuggingFaceEmbeddings kullan
    embeddings = HuggingFaceEmbeddings(model_name=model_name)
    print("âœ… Embedding modeli hazÄ±r")

    print("\nğŸ” Vector Database (FAISS) oluÅŸturuluyor...")
    print("â³ Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir...")

    vector_store = FAISS.from_documents(chunks, embeddings)

    print(f"âœ… FAISS Vector Database baÅŸarÄ±yla oluÅŸturuldu!")
    print(f"ğŸ“Š Toplam vektÃ¶r sayÄ±sÄ±: {len(chunks)}")
    print()

except Exception as e:
    print(f"âŒ Embedding veya Vector DB hatasÄ±: {e}")
    raise

# ============================================================================
# 7. RAG CHAIN (CHATBOT BEYNÄ°) KURULUMU
# ============================================================================

print("=" * 70)
print("ADIM 7: RAG Chain (Retrieval Augmented Generation) Kuruluyor...")
print("=" * 70)

"""
RAG MÄ°MARÄ°SÄ° AÃ‡IKLAMASI:

1. RETRIEVAL (Bilgi Getirme):
   - KullanÄ±cÄ± sorusu embedding'e Ã§evriliyor
   - Vector DB'de similarity search yapÄ±lÄ±yor
   - En alakalÄ± k=10 chunk getiriliyor

2. AUGMENTATION (BaÄŸlam ZenginleÅŸtirme):
   - Getirilen chunk'lar birleÅŸtiriliyor
   - LLM'e context olarak veriliyor

3. GENERATION (Cevap Ãœretme):
   - Gemini 2.5 Flash context'i okuyup cevap Ã¼retiyor
   - Temperature=0.1 (tutarlÄ± cevaplar iÃ§in)

NEDEN RAG?
- LLM'in bilgisi sÄ±nÄ±rlÄ± (training cutoff)
- PDF'deki gÃ¼ncel/spesifik bilgiyi kullanabiliyor
- Hallusinasyon riski azalÄ±yor (kaynak var)
"""

try:
    # LLM KonfigÃ¼rasyonu
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",  # En gÃ¼ncel Gemini modeli
        temperature=0.1,  # DÃ¼ÅŸÃ¼k = daha tutarlÄ±/gerÃ§ekÃ§i cevaplar
    )

    # Retriever KonfigÃ¼rasyonu
    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 10}  # En benzer 10 chunk getir
    )

    # QA Chain OluÅŸturma
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",  # TÃ¼m context'i tek seferde LLM'e ver
        retriever=retriever,
        return_source_documents=True  # Kaynak chunk'larÄ± da dÃ¶ndÃ¼r
    )

    print("âœ… RAG Chain baÅŸarÄ±yla kuruldu!")
    print(f"ğŸ¤– LLM: Gemini 2.0 Flash")
    print(f"ğŸ” Retriever: FAISS (k=10)")
    print(f"ğŸŒ¡ï¸ Temperature: 0.1")
    print()

except Exception as e:
    print(f"âŒ RAG Chain kurulum hatasÄ±: {e}")
    qa_chain = None
    raise

# ============================================================================
# 8. CHATBOT FONKSÄ°YONU
# ============================================================================

def ask_question(question, show_sources=False):
    """
    Chatbot'a soru sorma fonksiyonu

    Args:
        question (str): KullanÄ±cÄ±nÄ±n sorusu
        show_sources (bool): Kaynak chunk'larÄ± gÃ¶ster/gÃ¶sterme

    Returns:
        dict: Cevap ve kaynak bilgileri
    """
    print("\n" + "=" * 70)
    print(f"â“ SORU: {question}")
    print("=" * 70)

    if qa_chain is None:
        print("âŒ RAG Chain tanÄ±mlÄ± deÄŸil!")
        return None

    try:
        # Soru-cevap iÅŸlemi
        result = qa_chain.invoke({"query": question})

        print(f"\nğŸ’¬ CEVAP:")
        print("-" * 70)
        print(result['result'])
        print("-" * 70)

        # Kaynak dÃ¶kÃ¼manlarÄ± gÃ¶ster
        if show_sources and 'source_documents' in result:
            print(f"\nğŸ“š KULLANILAN KAYNAKLAR ({len(result['source_documents'])} adet):")
            for i, doc in enumerate(result['source_documents'][:3], 1):  # Ä°lk 3'Ã¼ gÃ¶ster
                print(f"\n[Kaynak {i}] Sayfa {doc.metadata.get('page', 'N/A')}:")
                print(doc.page_content[:200] + "...")

        return result

    except Exception as e:
        print(f"âŒ Soru iÅŸleme hatasÄ±: {e}")
        return None

# ============================================================================
# 9. TEST SORULARI VE DEÄERLENDÄ°RME
# ============================================================================

print("=" * 70)
print("ADIM 9: Test SorularÄ± ile Chatbot Deneniyor...")
print("=" * 70)

# Test sorularÄ±
test_questions = [
    "Arbitraj nedir?",
    "Enflasyon kelimesinin anlamÄ±nÄ± aÃ§Ä±klar mÄ±sÄ±n?",
    "Deflasyon nedir?",
    "Merkez bankasÄ± ne iÅŸ yapar?",
    "DevalÃ¼asyon ile revalÃ¼asyon arasÄ±ndaki fark nedir?"
]

print("\nğŸ§ª 5 farklÄ± ekonomi terimi ile test ediliyor...\n")

results = []
for i, question in enumerate(test_questions, 1):
    print(f"\n{'#' * 70}")
    print(f"TEST {i}/{len(test_questions)}")
    print(f"{'#' * 70}")

    result = ask_question(question, show_sources=True)
    results.append({
        'question': question,
        'answer': result['result'] if result else None,
        'success': result is not None
    })

    print("\n" + "â³ " * 20)

# ============================================================================
# 10. SONUÃ‡LAR VE Ä°STATÄ°STÄ°KLER
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ“Š TEST SONUÃ‡LARI ve Ä°STATÄ°STÄ°KLER")
print("=" * 70)

successful = sum(1 for r in results if r['success'])
print(f"\nâœ… BaÅŸarÄ±lÄ± sorgu: {successful}/{len(results)}")
print(f"ğŸ“ˆ BaÅŸarÄ± oranÄ±: {(successful/len(results)*100):.1f}%")

print("\nğŸ’¡ PROJE KAZANIMLARI:")
print("  âœ“ PDF'den bilgi Ã§ekme")
print("  âœ“ Semantic search ile ilgili parÃ§alarÄ± bulma")
print("  âœ“ LLM ile doÄŸal dil cevaplarÄ±")
print("  âœ“ TÃ¼rkÃ§e dil desteÄŸi")
print("  âœ“ Kaynak referanslarÄ±")

print("\n" + "=" * 70)
print("ğŸ‰ PROJE BAÅARIYLA TAMAMLANDI!")
print("=" * 70)

print("\nğŸ“ SONRAKI ADIMLAR:")
print("1. Web arayÃ¼zÃ¼ geliÅŸtirin (Streamlit/Gradio)")
print("2. README.md dosyasÄ±nÄ± oluÅŸturun")
print("3. requirements.txt hazÄ±rlayÄ±n")
print("4. GitHub'a yÃ¼kleyin")
print("5. Deploy edin (Hugging Face Spaces/Streamlit Cloud)")
print("\n" + "=" * 70)

# requirements.txt oluÅŸtur/gÃ¼ncelle
requirements_content = """
langchain==0.3.27
langchain-community==0.3.31
langchain-google-genai==2.1.12
langchain-huggingface==0.1.0
sentence-transformers==3.1.1
faiss-cpu
pypdf
protobuf==4.25.5
numpy==1.26.4
streamlit
google-generativeai
"""

with open('/content/requirements.txt', 'w') as f:
    f.write(requirements_content.strip())

print("âœ… requirements.txt baÅŸarÄ±yla oluÅŸturuldu/gÃ¼ncellendi!")
print("ğŸ“„ Ä°Ã§erik:")
with open('/content/requirements.txt', 'r') as f:
    print(f.read())

# ============================================================================
# 11. GRADIO WEB ARAYÃœZÃœ
# ============================================================================

print("\n" + "=" * 70)
print("ADIM 11: Gradio Web ArayÃ¼zÃ¼ BaÅŸlatÄ±lÄ±yor...")
print("=" * 70)

# Gradio kurulumu
!pip install gradio -q

import gradio as gr
from datetime import datetime

def chatbot_interface(message, history):
    """
    Gradio chatbot fonksiyonu

    Args:
        message (str): KullanÄ±cÄ±nÄ±n mesajÄ±
        history (list): Sohbet geÃ§miÅŸi (messages format)

    Returns:
        tuple: (BoÅŸ string, gÃ¼ncellenmiÅŸ history)
    """
    if not message.strip():
        return "", history

    try:
        # RAG chain ile cevap al
        result = qa_chain.invoke({"query": message})
        answer = result['result']

        # Kaynak bilgisi ekle (isteÄŸe baÄŸlÄ±)
        if 'source_documents' in result and len(result['source_documents']) > 0:
            sources = set()
            for doc in result['source_documents'][:3]:
                page = doc.metadata.get('page', 'N/A')
                sources.add(f"Sayfa {page}")

            if sources:
                answer += f"\n\nğŸ“š *Kaynaklar: {', '.join(sorted(sources))}*"

        # History'ye ekle (messages formatÄ±nda - dictionary)
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": answer})
        return "", history

    except Exception as e:
        error_msg = f"âŒ Bir hata oluÅŸtu: {str(e)}"
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": error_msg})
        return "", history

# Gradio arayÃ¼zÃ¼ tasarÄ±mÄ±
with gr.Blocks(
    theme=gr.themes.Soft(),
    title="ğŸ“š Ekonomi Terimleri Chatbot"
) as demo:

    gr.Markdown(
        """
        # ğŸ“š Ekonomi Terimleri RAG Chatbot
        ### Powered by Google Gemini 2.0 Flash & LangChain

        Bu chatbot, yÃ¼klediÄŸiniz ekonomi sÃ¶zlÃ¼ÄŸÃ¼ PDF'inden bilgi Ã§ekerek sorularÄ±nÄ±zÄ± yanÄ±tlar.
        **RAG (Retrieval Augmented Generation)** teknolojisi kullanÄ±r.
        """
    )

    with gr.Row():
        with gr.Column(scale=2):
            # Chatbot arayÃ¼zÃ¼
            chatbot = gr.Chatbot(
                label="Sohbet",
                height=500,
                bubble_full_width=False,
                avatar_images=(None, "ğŸ¤–"),
                type="messages"  # Modern format
            )

            with gr.Row():
                msg = gr.Textbox(
                    label="Sorunuzu yazÄ±n",
                    placeholder="Ã–rn: Arbitraj nedir?",
                    scale=4,
                    lines=1
                )
                submit = gr.Button("ğŸ“¤ GÃ¶nder", variant="primary", scale=1)

            with gr.Row():
                clear = gr.Button("ğŸ—‘ï¸ Sohbeti Temizle")

        with gr.Column(scale=1):
            gr.Markdown(
                """
                ### ğŸ’¡ Ã–rnek Sorular

                - Arbitraj nedir?
                - Enflasyon ne demek?
                - Deflasyon ile enflasyon farkÄ± nedir?
                - Merkez bankasÄ± ne iÅŸ yapar?
                - DevalÃ¼asyon aÃ§Ä±kla
                - RevalÃ¼asyon nedir?
                - DÃ¶viz kuru nasÄ±l belirlenir?

                ### â„¹ï¸ Bilgi

                **Model:** Gemini 2.0 Flash
                **Embedding:** Multilingual MiniLM
                **Vector DB:** FAISS
                **Toplam Chunk:** """ + str(len(chunks)) + """
                **Retrieval:** Top-10 Similarity

                ### ğŸ“Š Ä°statistikler

                - âœ… RAG Chain Aktif
                - ğŸ” Semantic Search Etkin
                - ğŸŒ TÃ¼rkÃ§e Destek
                - ğŸ“„ PDF Kaynak ReferansÄ±
                """
            )

    gr.Markdown(
        """
        ---
        <center>

        Made with â¤ï¸ using LangChain & Gradio |
        [GitHub](https://github.com) |
        [Documentation](https://docs.langchain.com)

        </center>
        """
    )

    # Event handlers
    submit.click(
        fn=chatbot_interface,
        inputs=[msg, chatbot],
        outputs=[msg, chatbot]
    )

    msg.submit(
        fn=chatbot_interface,
        inputs=[msg, chatbot],
        outputs=[msg, chatbot]
    )

    clear.click(
        fn=lambda: ([], ""),
        inputs=None,
        outputs=[chatbot, msg]
    )

# ArayÃ¼zÃ¼ baÅŸlat
print("\nâœ… Gradio arayÃ¼zÃ¼ hazÄ±r!")
print("ğŸŒ AÅŸaÄŸÄ±daki linkten eriÅŸebilirsiniz...\n")

# Public link ile baÅŸlat (Colab'da Ã§alÄ±ÅŸmasÄ± iÃ§in)
demo.launch(
    share=True,  # Public link oluÅŸtur
    debug=True,
    show_error=True
)

print("\n" + "=" * 70)
print("ğŸ‰ WEB ARAYÃœZÃœ BAÅARIYLA BAÅLATILDI!")
print("=" * 70)
print("\nğŸ’¡ Ä°PUCU: Gradio arayÃ¼zÃ¼nÃ¼ kapatmak iÃ§in 'Kernel > Interrupt' yapÄ±n.")